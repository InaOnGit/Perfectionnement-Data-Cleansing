# Travaux Pratiques - Data Cleansing

Collection de notebooks Jupyter sur le nettoyage de donnÃ©es avec Python.

---

## ğŸ“š Contenu

### TP1 - DÃ©couverte et Valeurs Manquantes Simples
**DifficultÃ©:** DÃ©butant  
**Dataset:** `ecommerce_simple.csv`  
**Objectif:** Introduction au nettoyage avec gestion basique des valeurs manquantes

### TP2 - Doublons et Standardisation
**DifficultÃ©:** DÃ©butant  
**Dataset:** `customers_duplicates.csv`  
**Objectif:** DÃ©tection et suppression des doublons, standardisation des formats

---

## ğŸ“Š TP1 - Valeurs Manquantes

### Concepts abordÃ©s

- **DÃ©tection des valeurs manquantes**
  - Comptage avec `df.isnull().sum()`
  - Calcul des pourcentages
  - Visualisation avec `missingno`

- **StratÃ©gies d'imputation**
  - **MÃ©diane** pour variables numÃ©riques (rÃ©sistante aux outliers)
  - **Mode** pour variables catÃ©gorielles (valeur la plus frÃ©quente)
  - Suppression de colonnes avec >70% de valeurs manquantes

- **Analyse exploratoire (EDA)**
  - `df.head()`, `df.info()`, `df.describe()`
  - CorrÃ©lations entre variables
  - Distribution des donnÃ©es

### Ã‰tapes du TP

1. Import et exploration du dataset (500 lignes, 8 colonnes)
2. Analyse des informations gÃ©nÃ©rales
3. Calcul du pourcentage de valeurs manquantes par colonne
4. Suppression des colonnes avec >70% de valeurs manquantes
5. Remplissage des valeurs numÃ©riques avec la mÃ©diane
6. Remplissage des valeurs catÃ©gorielles avec le mode
7. VÃ©rification de l'absence de valeurs manquantes
8. RÃ©sumÃ© des transformations effectuÃ©es

### MÃ©triques clÃ©s

| MÃ©trique | Avant | AprÃ¨s |
|----------|-------|-------|
| Colonnes avec valeurs manquantes | Variable | 0 |
| Valeurs manquantes totales | Variable | 0 |

### Code exemple

```python
# Remplir avec mÃ©diane
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
for col in numeric_cols:
    if df[col].isnull().sum() > 0:
        median_value = df[col].median()
        df[col].fillna(median_value, inplace=True)

# Remplir avec mode
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    if df[col].isnull().sum() > 0:
        mode_value = df[col].mode()[0]
        df[col].fillna(mode_value, inplace=True)
```

---

## ğŸ”„ TP2 - Doublons et Standardisation

### Concepts abordÃ©s

- **DÃ©tection de doublons**
  - Doublons exacts avec `df.duplicated()`
  - Identification des lignes en doublon
  - Pourcentage de duplication

- **Suppression de doublons**
  - Conservation de la premiÃ¨re occurrence avec `keep='first'`
  - Impact sur la taille du dataset

- **Standardisation des donnÃ©es**
  - **Casse** : emails en minuscules, noms en title case
  - **Espaces** : suppression avec `.str.strip()`
  - **CatÃ©gories** : mapping pour unifier les variations (M/Male/m â†’ Male)
  - **Formats** : tÃ©lÃ©phones au format international

### Ã‰tapes du TP

1. Identification et comptage des doublons exacts
2. Affichage d'exemples de doublons
3. Suppression des doublons (conservation de la premiÃ¨re occurrence)
4. Standardisation de la casse (emails, noms)
5. Suppression des espaces en dÃ©but/fin de chaÃ®nes
6. CrÃ©ation de mappings pour les catÃ©gories
7. Application des mappings
8. Standardisation des formats de tÃ©lÃ©phone
9. VÃ©rification des doublons restants aprÃ¨s standardisation
10. CrÃ©ation du rapport de nettoyage

### Transformations appliquÃ©es

#### Standardisation de la casse
```python
df['email'] = df['email'].str.lower()
df['name'] = df['name'].str.title()
```

#### Mapping des catÃ©gories
```python
gender_mapping = {
    'M': 'Male', 'm': 'Male', 'Male': 'Male',
    'F': 'Female', 'f': 'Female', 'Female': 'Female'
}
df['gender'] = df['gender'].map(gender_mapping)
```

#### Standardisation des tÃ©lÃ©phones
```python
import re
def clean_phone(phone):
    cleaned = re.sub(r'\D', '', str(phone))
    return f"+{cleaned[:2]} {cleaned[2:5]} {cleaned[5:8]} {cleaned[8:]}"

df['phone'] = df['phone'].apply(clean_phone)
```

### MÃ©triques clÃ©s

| MÃ©trique | Valeur |
|----------|--------|
| Doublons supprimÃ©s | Variable selon dataset |
| Taux de compression | Variable |
| CatÃ©gories standardisÃ©es | Gender, Country, etc. |
| Formats unifiÃ©s | TÃ©lÃ©phones, emails |

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python** 3.12
- **pandas** : Manipulation de donnÃ©es
- **numpy** : Calculs numÃ©riques
- **matplotlib** : Visualisations
- **seaborn** : Graphiques statistiques
- **missingno** : Visualisation des valeurs manquantes
- **scipy** : Statistiques (TP3+)

---

## ğŸ“¦ Installation

```bash
pip install pandas numpy matplotlib seaborn missingno scipy
```

Ou avec le fichier requirements.txt :

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Utilisation

1. Cloner le repository
```bash
git clone https://github.com/[votre-username]/data-cleansing-tp.git
cd data-cleansing-tp
```

2. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

3. Ouvrir un notebook
```bash
jupyter notebook TP1_Data_Cleansing_COMPLETED.ipynb
```

---

## ğŸ“ Structure des notebooks

Chaque TP suit une structure cohÃ©rente :

1. **Imports** : BibliothÃ¨ques nÃ©cessaires
2. **Import du dataset** : Chargement des donnÃ©es
3. **Visualisation** : Analyse des valeurs manquantes
4. **Questions prÃ©alables** : 10 questions avec rÃ©ponses
5. **Ã‰tapes du TP** : 8-10 Ã©tapes guidÃ©es
6. **Rapport final** : RÃ©sumÃ© des transformations

---

## ğŸ¯ CompÃ©tences dÃ©veloppÃ©es

### TP1
- âœ… DÃ©tection et analyse des valeurs manquantes
- âœ… Choix de stratÃ©gies d'imputation appropriÃ©es
- âœ… Utilisation de mÃ©dianes et modes
- âœ… Manipulation de DataFrames pandas
- âœ… Visualisation de donnÃ©es

### TP2
- âœ… DÃ©tection de doublons
- âœ… DÃ©duplication de donnÃ©es
- âœ… Standardisation de formats
- âœ… Nettoyage de chaÃ®nes de caractÃ¨res
- âœ… Mapping de catÃ©gories
- âœ… Expressions rÃ©guliÃ¨res (regex)

---

## ğŸ“– Ressources

### Documentation
- [pandas Documentation](https://pandas.pydata.org/docs/)
- [missingno Documentation](https://github.com/ResidentMario/missingno)
- [Guide de nettoyage de donnÃ©es](https://www.kaggle.com/learn/data-cleaning)

### Concepts clÃ©s

**Pourquoi la mÃ©diane plutÃ´t que la moyenne ?**
- La mÃ©diane est rÃ©sistante aux valeurs extrÃªmes
- Exemple : [10, 20, 30, 1000] â†’ moyenne=265, mÃ©diane=25
- Pour des donnÃ©es avec outliers, la mÃ©diane est plus reprÃ©sentative

**Pourquoi le mode pour les catÃ©gories ?**
- Le mode prÃ©serve la distribution des catÃ©gories
- C'est la valeur la plus probable statistiquement
- Ã‰vite d'introduire des valeurs qui n'existent pas dans les donnÃ©es

**Quand supprimer vs imputer ?**
- Supprimer si >70% de valeurs manquantes
- Imputer si les valeurs manquantes sont alÃ©atoires (MCAR)
- Analyser le pattern de missingness avant de dÃ©cider

---

## âš ï¸ Remarques importantes

### Bonnes pratiques
- Toujours travailler sur une copie du dataset : `df_clean = df.copy()`
- Documenter chaque transformation
- VÃ©rifier les rÃ©sultats aprÃ¨s chaque Ã©tape
- CrÃ©er un rapport de nettoyage

### Erreurs courantes Ã  Ã©viter
- âŒ Oublier `inplace=True` ou rÃ©assigner : `df['col'] = df['col'].fillna(value)`
- âŒ Ne pas vÃ©rifier le type de donnÃ©es avant imputation
- âŒ Utiliser `.mean()` au lieu de `.median()` pour donnÃ©es avec outliers
- âŒ Oublier `[0]` pour `.mode()` : `mode_value = df['col'].mode()[0]`

---

## ğŸ‘¤ Auteur

Travaux rÃ©alisÃ©s dans le cadre d'un cours de Data Science et Machine Learning.

---

## ğŸ“… Date

Janvier 2026

---

## ğŸ”œ Prochains TP

- **TP3** : DÃ©tection et traitement des outliers (IQR, Z-score)
- **TP4** : Validation et cohÃ©rence des donnÃ©es
- **TP5** : Imputation avancÃ©e (KNN, MICE)
- **TP6** : Encodage et Feature Engineering
- **TP7** : Normalisation et Pipeline Sklearn
- **TP8** : DÃ©tection de doublons flous (Fuzzy Matching)
- **TP9** : Pipeline automatisÃ© de bout en bout

---

## ğŸ“Š Statistiques

- **Notebooks complÃ©tÃ©s** : 2/9
- **Concepts maÃ®trisÃ©s** : Valeurs manquantes, Doublons, Standardisation
- **Lignes de code** : ~500+
- **Datasets nettoyÃ©s** : 2

---

## ğŸ¤ Contribution

Ce projet est Ã  usage Ã©ducatif. Les suggestions d'amÃ©lioration sont les bienvenues !

---

## ğŸ“„ Licence

Usage acadÃ©mique uniquement.
